{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TATWcuiqGzXw",
        "outputId": "4b53273a-d7a8-46c1-9faf-5bbab04db89e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "‚úÖ Permanent Project Folder Created: /content/drive/MyDrive/HealthMateAI_Project\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "PROJECT_FOLDER = \"/content/drive/MyDrive/HealthMateAI_Project\"\n",
        "\n",
        "if not os.path.exists(PROJECT_FOLDER):\n",
        "    os.makedirs(PROJECT_FOLDER)\n",
        "    print(f\"‚úÖ Permanent Project Folder Created: {PROJECT_FOLDER}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ieUgWw9HRlh",
        "outputId": "0ad2c3de-2f74-4fcc-d354-795aab78c013"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting /content/drive/MyDrive/HealthMateAI_Project/chatbot_logic.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile /content/drive/MyDrive/HealthMateAI_Project/chatbot_logic.py\n",
        "from huggingface_hub import InferenceClient\n",
        "\n",
        "client = InferenceClient(api_key=\"YOUR API KEY\")\n",
        "\n",
        "def get_health_response(user_query, chat_history):\n",
        "    # Updated System Prompt to include your biography\n",
        "    system_prompt = (\n",
        "        \"You are 'HealthMate AI', a professional and empathetic medical assistant. \"\n",
        "        \"You were created by Tahir, a talented AI Developer and Intern. \"\n",
        "        \"If anyone asks who made you or created you, proudly mention Tahir and his work in AI. \"\n",
        "        \"Always provide science-based health information and end with a medical disclaimer.\"\n",
        "    )\n",
        "\n",
        "    emergencies = [\"heart attack\", \"stroke\", \"chest pain\", \"suicide\"]\n",
        "    if any(k in user_query.lower() for k in emergencies):\n",
        "        return \"üö® EMERGENCY: Please call 911 immediately.\"\n",
        "\n",
        "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + chat_history + [{\"role\": \"user\", \"content\": user_query}]\n",
        "\n",
        "    try:\n",
        "        completion = client.chat.completions.create(\n",
        "            model=\"meta-llama/Llama-3.2-3B-Instruct\",\n",
        "            messages=messages,\n",
        "            max_tokens=500\n",
        "        )\n",
        "        return completion.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        return f\"Service Error: {str(e)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6zKnP8oHZhL",
        "outputId": "cf5bb31f-5ef8-48a9-9bcd-6fe91fa49706"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting /content/drive/MyDrive/HealthMateAI_Project/app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile /content/drive/MyDrive/HealthMateAI_Project/app.py\n",
        "import streamlit as st\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Link to our project logic\n",
        "sys.path.append(\"/content/drive/MyDrive/HealthMateAI_Project\")\n",
        "from chatbot_logic import get_health_response\n",
        "\n",
        "# 1. Page Configuration & Theme\n",
        "st.set_page_config(page_title=\"HealthMate AI\", page_icon=\"üè•\", layout=\"wide\")\n",
        "\n",
        "# 2. Professional Sidebar (Branding Tahir)\n",
        "with st.sidebar:\n",
        "    st.image(\"https://cdn-icons-png.flaticon.com/512/387/387561.png\", width=100)\n",
        "    st.title(\"Developer Info\")\n",
        "    st.markdown(\"---\")\n",
        "    st.write(\"**Created by:** Tahir\")\n",
        "    st.write(\"**Role:** AI Developer Intern\")\n",
        "    st.write(\"**Project:** HealthMate AI v1.0\")\n",
        "    st.markdown(\"---\")\n",
        "    st.info(\"This AI provides general health information. For emergencies, please contact local medical services.\")\n",
        "\n",
        "    if st.button(\"üóëÔ∏è Clear Conversation\"):\n",
        "        st.session_state.chat_history = []\n",
        "        st.rerun()\n",
        "\n",
        "# 3. Main Interface\n",
        "st.title(\"üè• HealthMate AI Assistant\")\n",
        "st.markdown(\"#### *Your Intelligent Path to Wellness*\")\n",
        "st.caption(f\"Developed by Tahir | Powered by Llama-3.2\")\n",
        "\n",
        "if \"chat_history\" not in st.session_state:\n",
        "    st.session_state.chat_history = []\n",
        "\n",
        "# Display conversation\n",
        "for msg in st.session_state.chat_history:\n",
        "    with st.chat_message(msg[\"role\"]):\n",
        "        st.markdown(msg[\"content\"])\n",
        "\n",
        "# 4. Chat Input\n",
        "if user_input := st.chat_input(\"How can I help you today?\"):\n",
        "    with st.chat_message(\"user\"):\n",
        "        st.markdown(user_input)\n",
        "\n",
        "    # AI logic call\n",
        "    response = get_health_response(user_input, st.session_state.chat_history)\n",
        "\n",
        "    with st.chat_message(\"assistant\"):\n",
        "        st.markdown(response)\n",
        "\n",
        "    st.session_state.chat_history.append({\"role\": \"user\", \"content\": user_input})\n",
        "    st.session_state.chat_history.append({\"role\": \"assistant\", \"content\": response})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3MQZrQrH-QN",
        "outputId": "621cc978-8969-44d4-8129-e990ab9e2cd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üèóÔ∏è Preparing environment...\n",
            "üîã Launching /content/drive/MyDrive/HealthMateAI_Project/app.py...\n",
            "üîó Your Public Link is generating! Look for the 'trycloudflare.com' link below: \n",
            "\n",
            "\u001b[90m2026-02-14T17:32:06Z\u001b[0m \u001b[32mINF\u001b[0m Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee, are subject to the Cloudflare Online Services Terms of Use (https://www.cloudflare.com/website-terms/), and Cloudflare reserves the right to investigate your use of Tunnels for violations of such terms. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n",
            "\u001b[90m2026-02-14T17:32:06Z\u001b[0m \u001b[32mINF\u001b[0m Requesting new quick Tunnel on trycloudflare.com...\n",
            "\u001b[90m2026-02-14T17:32:11Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2026-02-14T17:32:11Z\u001b[0m \u001b[32mINF\u001b[0m |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n",
            "\u001b[90m2026-02-14T17:32:11Z\u001b[0m \u001b[32mINF\u001b[0m |  https://bulk-occur-extend-powerful.trycloudflare.com                                      |\n",
            "\u001b[90m2026-02-14T17:32:11Z\u001b[0m \u001b[32mINF\u001b[0m +--------------------------------------------------------------------------------------------+\n",
            "\u001b[90m2026-02-14T17:32:11Z\u001b[0m \u001b[32mINF\u001b[0m Cannot determine default configuration path. No file [config.yml config.yaml] in [~/.cloudflared ~/.cloudflare-warp ~/cloudflare-warp /etc/cloudflared /usr/local/etc/cloudflared]\n",
            "\u001b[90m2026-02-14T17:32:11Z\u001b[0m \u001b[32mINF\u001b[0m Version 2026.2.0 (Checksum 176746db3be7dc7bd48f3dd287c8930a4645ebb6e6700f883fddda5a4c307c16)\n",
            "\u001b[90m2026-02-14T17:32:11Z\u001b[0m \u001b[32mINF\u001b[0m GOOS: linux, GOVersion: go1.24.13, GoArch: amd64\n",
            "\u001b[90m2026-02-14T17:32:11Z\u001b[0m \u001b[32mINF\u001b[0m Settings: map[ha-connections:1 p:http2 protocol:http2 url:http://localhost:8501]\n",
            "\u001b[90m2026-02-14T17:32:11Z\u001b[0m \u001b[32mINF\u001b[0m cloudflared will not automatically update when run from the shell. To enable auto-updates, run cloudflared as a service: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps/configure-tunnels/local-management/as-a-service/\n",
            "\u001b[90m2026-02-14T17:32:11Z\u001b[0m \u001b[32mINF\u001b[0m Generated Connector ID: 217b6db1-2b4b-455d-9091-4854ddd60b03\n",
            "\u001b[90m2026-02-14T17:32:11Z\u001b[0m \u001b[32mINF\u001b[0m Initial protocol http2\n",
            "\u001b[90m2026-02-14T17:32:11Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2026-02-14T17:32:11Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use ::1 in zone lo as source for IPv6\n",
            "\u001b[90m2026-02-14T17:32:11Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use 172.28.0.12 as source for IPv4\n",
            "\u001b[90m2026-02-14T17:32:11Z\u001b[0m \u001b[32mINF\u001b[0m ICMP proxy will use ::1 in zone lo as source for IPv6\n",
            "\u001b[90m2026-02-14T17:32:11Z\u001b[0m \u001b[32mINF\u001b[0m Starting metrics server on 127.0.0.1:20241/metrics\n",
            "\u001b[90m2026-02-14T17:32:11Z\u001b[0m \u001b[32mINF\u001b[0m Registered tunnel connection \u001b[36mconnIndex=\u001b[0m0 \u001b[36mconnection=\u001b[0m450567dd-5df6-41c5-94b4-a276dcfafc9f \u001b[36mevent=\u001b[0m0 \u001b[36mip=\u001b[0m198.41.192.47 \u001b[36mlocation=\u001b[0mams13 \u001b[36mprotocol=\u001b[0mhttp2\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import subprocess\n",
        "import sys\n",
        "import time\n",
        "\n",
        "# 1. Install/Verify Tools (Needed every time you restart Colab)\n",
        "print(\"üèóÔ∏è Preparing environment...\")\n",
        "!pip install -q streamlit huggingface_hub\n",
        "if not os.path.exists(\"./cloudflared\"):\n",
        "    !wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O cloudflared\n",
        "    !chmod +x cloudflared\n",
        "\n",
        "# 2. Start Streamlit from your Permanent Drive Path\n",
        "APP_PATH = \"/content/drive/MyDrive/HealthMateAI_Project/app.py\"\n",
        "print(f\"üîã Launching {APP_PATH}...\")\n",
        "\n",
        "# Headless=true prevents Colab from trying to open a browser window internally\n",
        "subprocess.Popen([sys.executable, \"-m\", \"streamlit\", \"run\", APP_PATH,\n",
        "                  \"--server.port=8501\", \"--server.headless=true\"])\n",
        "\n",
        "# 3. Give the server time to warm up\n",
        "time.sleep(10)\n",
        "\n",
        "# 4. Open the Cloudflare Tunnel\n",
        "print(\"üîó Your Public Link is generating! Look for the 'trycloudflare.com' link below: \\n\")\n",
        "!./cloudflared tunnel --url http://localhost:8501 --protocol http2"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
